{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Are We Doing?\n",
    "\n",
    "In the last notebook, you created a working version of SVD for situations even when there are tons of missing values.  This is awesome!  The question now is how well does this solution work?\n",
    "\n",
    "In this notebook, we are going to simulate exactly what we would do in the real world to tune our recommender.  \n",
    "\n",
    "Run the cell below to read in the data and get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('data/movies_clean.csv')\n",
    "reviews = pd.read_csv('data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Using the **reviews** dataframe, perform the following tasks to create a training and validation set of data we can use to test the performance of your SVD algorithm using **off-line** validation techniques.\n",
    "\n",
    " * Order the reviews dataframe from earliest to most recent \n",
    " * Pull the first 10000 reviews from  the dataset\n",
    " * Make the first 8000/10000 reviews the training data \n",
    " * Make the last 2000/10000 the test data\n",
    " * Return the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>date</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>...</th>\n",
       "      <th>month_9</th>\n",
       "      <th>month_10</th>\n",
       "      <th>month_11</th>\n",
       "      <th>month_12</th>\n",
       "      <th>year_2013</th>\n",
       "      <th>year_2014</th>\n",
       "      <th>year_2015</th>\n",
       "      <th>year_2016</th>\n",
       "      <th>year_2017</th>\n",
       "      <th>year_2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>498923</th>\n",
       "      <td>37287</td>\n",
       "      <td>2171847</td>\n",
       "      <td>6</td>\n",
       "      <td>1362062307</td>\n",
       "      <td>2013-02-28 14:38:27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442554</th>\n",
       "      <td>33140</td>\n",
       "      <td>444778</td>\n",
       "      <td>8</td>\n",
       "      <td>1362062624</td>\n",
       "      <td>2013-02-28 14:43:44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81920</th>\n",
       "      <td>6338</td>\n",
       "      <td>1411238</td>\n",
       "      <td>6</td>\n",
       "      <td>1362062838</td>\n",
       "      <td>2013-02-28 14:47:18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584570</th>\n",
       "      <td>43691</td>\n",
       "      <td>1496422</td>\n",
       "      <td>7</td>\n",
       "      <td>1362063503</td>\n",
       "      <td>2013-02-28 14:58:23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450669</th>\n",
       "      <td>33799</td>\n",
       "      <td>118799</td>\n",
       "      <td>5</td>\n",
       "      <td>1362063653</td>\n",
       "      <td>2013-02-28 15:00:53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  movie_id  rating   timestamp                 date  month_1  \\\n",
       "498923    37287   2171847       6  1362062307  2013-02-28 14:38:27        0   \n",
       "442554    33140    444778       8  1362062624  2013-02-28 14:43:44        0   \n",
       "81920      6338   1411238       6  1362062838  2013-02-28 14:47:18        0   \n",
       "584570    43691   1496422       7  1362063503  2013-02-28 14:58:23        0   \n",
       "450669    33799    118799       5  1362063653  2013-02-28 15:00:53        0   \n",
       "\n",
       "        month_2  month_3  month_4  month_5    ...      month_9  month_10  \\\n",
       "498923        0        0        0        0    ...            0         0   \n",
       "442554        0        0        0        0    ...            0         0   \n",
       "81920         0        0        0        0    ...            0         0   \n",
       "584570        0        0        0        0    ...            0         0   \n",
       "450669        0        0        0        0    ...            0         0   \n",
       "\n",
       "        month_11  month_12  year_2013  year_2014  year_2015  year_2016  \\\n",
       "498923         0         0          1          0          0          0   \n",
       "442554         0         0          1          0          0          0   \n",
       "81920          0         0          1          0          0          0   \n",
       "584570         0         0          1          0          0          0   \n",
       "450669         0         0          1          0          0          0   \n",
       "\n",
       "        year_2017  year_2018  \n",
       "498923          0          0  \n",
       "442554          0          0  \n",
       "81920           0          0  \n",
       "584570          0          0  \n",
       "450669          0          0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.sort_values(by='timestamp').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(reviews, order_by='timestamp', \n",
    "                      training_size=8000, testing_size=2000):\n",
    "    '''    \n",
    "    INPUT:\n",
    "    reviews - (pandas df) dataframe to split into train and test\n",
    "    order_by - (string) column name to sort by\n",
    "    training_size - (int) number of rows in training set\n",
    "    testing_size - (int) number of columns in the test set\n",
    "    \n",
    "    OUTPUT:\n",
    "    training_df -  (pandas df) dataframe of the training set\n",
    "    validation_df - (pandas df) dataframe of the test set\n",
    "    '''\n",
    "    data = reviews.sort_values(by=order_by)\n",
    "    training_df = data.iloc[:training_size, :]\n",
    "    validation_df = data.iloc[training_size: training_size + testing_size, :]\n",
    "\n",
    "    return training_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to change in this or the next cell\n",
    "# Use our function to create training and test datasets\n",
    "train_df, val_df = create_train_test(reviews, 'date', 8000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the dataframes we are using are the right shape\n",
    "assert train_df.shape[0] == 8000, \"The number of rows doesn't look right in the training dataset.\"\n",
    "assert val_df.shape[0] == 2000, \"The number of rows doesn't look right in the validation dataset\"\n",
    "assert str(train_df.tail(1)['date']).split()[1] == '2013-03-15', \"The last date in the training dataset doesn't look like what we expected.\"\n",
    "assert str(val_df.tail(1)['date']).split()[1] == '2013-03-18', \"The last date in the validation dataset doesn't look like what we expected.\"\n",
    "print(\"Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world, we might have all of the data up to this final date in the training data.  Then we want to see how well we are doing for each of the new ratings, which show up in the test data.\n",
    "\n",
    "Below is a working example of the function created in the previous example you can use (or you can replace with your own).\n",
    "\n",
    "`2.`  Fit the function to the training data with the following hyperparameters: 15 latent features, a learning rate of 0.005, and 250 iterations. This will take some time to run, so you may choose fewer latent features, a higher learning rate, or fewer iteratios if you want to speed up the process.  \n",
    "\n",
    "**Note:** Again, this might be a good time to take a phone call, go for a walk, or just take a little break.  No need to change the code below unless you would like to make changes to reduce the time needed to obtain results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=12, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = ratings_mat.shape[0]\n",
    "    n_movies = ratings_mat.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # keep track of iteration and MSE\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "        tic = time()\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if ratings_mat[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "        toc = time()\n",
    "\n",
    "        # print results\n",
    "        print(\"%d \\t\\t %f  time: %f\" % (iteration+1, sse_accum / num_ratings, (toc - tic)))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 10.551063  time: 3.844598\n",
      "2 \t\t 5.895848  time: 3.911262\n",
      "3 \t\t 4.116195  time: 3.915029\n",
      "4 \t\t 3.078319  time: 3.842188\n",
      "5 \t\t 2.397350  time: 3.759900\n",
      "6 \t\t 1.917499  time: 3.780978\n",
      "7 \t\t 1.562773  time: 3.820272\n",
      "8 \t\t 1.291638  time: 3.807303\n",
      "9 \t\t 1.079281  time: 3.876336\n",
      "10 \t\t 0.909838  time: 3.923723\n",
      "11 \t\t 0.772645  time: 3.917997\n",
      "12 \t\t 0.660257  time: 4.128343\n",
      "13 \t\t 0.567308  time: 3.888708\n",
      "14 \t\t 0.489829  time: 3.894454\n",
      "15 \t\t 0.424809  time: 3.827314\n",
      "16 \t\t 0.369922  time: 3.804579\n",
      "17 \t\t 0.323338  time: 3.821382\n",
      "18 \t\t 0.283606  time: 3.854106\n",
      "19 \t\t 0.249558  time: 3.832867\n",
      "20 \t\t 0.220252  time: 3.892736\n",
      "21 \t\t 0.194925  time: 3.944671\n",
      "22 \t\t 0.172952  time: 3.889781\n",
      "23 \t\t 0.153823  time: 3.774048\n",
      "24 \t\t 0.137116  time: 3.787685\n",
      "25 \t\t 0.122482  time: 3.809096\n",
      "26 \t\t 0.109628  time: 3.809820\n",
      "27 \t\t 0.098311  time: 3.880027\n",
      "28 \t\t 0.088323  time: 3.890495\n",
      "29 \t\t 0.079490  time: 3.923731\n",
      "30 \t\t 0.071662  time: 3.860902\n",
      "31 \t\t 0.064711  time: 3.933229\n",
      "32 \t\t 0.058526  time: 3.809779\n",
      "33 \t\t 0.053013  time: 3.811594\n",
      "34 \t\t 0.048090  time: 3.756943\n",
      "35 \t\t 0.043687  time: 3.881626\n",
      "36 \t\t 0.039740  time: 3.931147\n",
      "37 \t\t 0.036198  time: 3.935844\n",
      "38 \t\t 0.033012  time: 3.969086\n",
      "39 \t\t 0.030143  time: 4.048741\n",
      "40 \t\t 0.027555  time: 3.973219\n",
      "41 \t\t 0.025217  time: 3.751753\n",
      "42 \t\t 0.023101  time: 3.770713\n",
      "43 \t\t 0.021183  time: 4.104736\n",
      "44 \t\t 0.019444  time: 4.139790\n",
      "45 \t\t 0.017863  time: 3.830522\n",
      "46 \t\t 0.016425  time: 3.874469\n",
      "47 \t\t 0.015116  time: 3.906569\n",
      "48 \t\t 0.013922  time: 4.164207\n",
      "49 \t\t 0.012832  time: 4.067366\n",
      "50 \t\t 0.011836  time: 3.883597\n",
      "51 \t\t 0.010925  time: 3.891730\n",
      "52 \t\t 0.010091  time: 3.840401\n",
      "53 \t\t 0.009327  time: 3.918152\n",
      "54 \t\t 0.008627  time: 3.982544\n",
      "55 \t\t 0.007984  time: 4.003474\n",
      "56 \t\t 0.007393  time: 4.015043\n",
      "57 \t\t 0.006850  time: 3.985689\n",
      "58 \t\t 0.006351  time: 3.934908\n",
      "59 \t\t 0.005891  time: 3.928972\n",
      "60 \t\t 0.005468  time: 3.976817\n",
      "61 \t\t 0.005077  time: 3.927002\n",
      "62 \t\t 0.004717  time: 4.201269\n",
      "63 \t\t 0.004385  time: 3.947939\n",
      "64 \t\t 0.004078  time: 4.058003\n",
      "65 \t\t 0.003795  time: 3.987495\n",
      "66 \t\t 0.003533  time: 4.042948\n",
      "67 \t\t 0.003290  time: 3.949691\n",
      "68 \t\t 0.003066  time: 3.789644\n",
      "69 \t\t 0.002858  time: 3.772611\n",
      "70 \t\t 0.002666  time: 3.811936\n",
      "71 \t\t 0.002487  time: 3.766653\n",
      "72 \t\t 0.002322  time: 3.812822\n",
      "73 \t\t 0.002169  time: 4.009266\n",
      "74 \t\t 0.002026  time: 3.995476\n",
      "75 \t\t 0.001894  time: 3.956601\n",
      "76 \t\t 0.001771  time: 3.985747\n",
      "77 \t\t 0.001656  time: 4.147409\n",
      "78 \t\t 0.001550  time: 3.910431\n",
      "79 \t\t 0.001451  time: 4.074854\n",
      "80 \t\t 0.001359  time: 4.051322\n",
      "81 \t\t 0.001273  time: 4.049407\n",
      "82 \t\t 0.001193  time: 4.053215\n",
      "83 \t\t 0.001119  time: 4.010677\n",
      "84 \t\t 0.001049  time: 4.453438\n",
      "85 \t\t 0.000984  time: 6.859101\n",
      "86 \t\t 0.000924  time: 6.187668\n",
      "87 \t\t 0.000867  time: 4.702080\n",
      "88 \t\t 0.000815  time: 4.399893\n",
      "89 \t\t 0.000765  time: 5.715325\n",
      "90 \t\t 0.000719  time: 5.699858\n",
      "91 \t\t 0.000676  time: 6.194046\n",
      "92 \t\t 0.000636  time: 5.232009\n",
      "93 \t\t 0.000598  time: 5.200091\n",
      "94 \t\t 0.000563  time: 5.238952\n",
      "95 \t\t 0.000530  time: 5.165198\n",
      "96 \t\t 0.000499  time: 5.311755\n",
      "97 \t\t 0.000470  time: 5.363596\n",
      "98 \t\t 0.000442  time: 4.584978\n",
      "99 \t\t 0.000417  time: 3.736204\n",
      "100 \t\t 0.000393  time: 3.764960\n",
      "101 \t\t 0.000370  time: 3.789571\n",
      "102 \t\t 0.000349  time: 3.793098\n",
      "103 \t\t 0.000330  time: 3.796550\n",
      "104 \t\t 0.000311  time: 3.787299\n",
      "105 \t\t 0.000293  time: 3.781854\n",
      "106 \t\t 0.000277  time: 3.753479\n",
      "107 \t\t 0.000262  time: 3.752502\n",
      "108 \t\t 0.000247  time: 3.789887\n",
      "109 \t\t 0.000233  time: 3.721578\n",
      "110 \t\t 0.000220  time: 3.813479\n",
      "111 \t\t 0.000208  time: 4.305338\n",
      "112 \t\t 0.000197  time: 5.590069\n",
      "113 \t\t 0.000186  time: 5.245849\n",
      "114 \t\t 0.000176  time: 4.656873\n",
      "115 \t\t 0.000167  time: 4.662294\n",
      "116 \t\t 0.000158  time: 4.625860\n",
      "117 \t\t 0.000149  time: 4.577460\n",
      "118 \t\t 0.000141  time: 4.635742\n",
      "119 \t\t 0.000134  time: 4.711294\n",
      "120 \t\t 0.000126  time: 4.901433\n",
      "121 \t\t 0.000120  time: 5.036490\n",
      "122 \t\t 0.000113  time: 5.431544\n",
      "123 \t\t 0.000107  time: 6.320314\n",
      "124 \t\t 0.000102  time: 5.456276\n",
      "125 \t\t 0.000096  time: 5.769715\n",
      "126 \t\t 0.000091  time: 4.703828\n",
      "127 \t\t 0.000087  time: 5.256060\n",
      "128 \t\t 0.000082  time: 5.271398\n",
      "129 \t\t 0.000078  time: 4.730535\n",
      "130 \t\t 0.000074  time: 4.618084\n",
      "131 \t\t 0.000070  time: 4.683686\n",
      "132 \t\t 0.000066  time: 4.750715\n",
      "133 \t\t 0.000063  time: 4.722900\n",
      "134 \t\t 0.000060  time: 4.954026\n",
      "135 \t\t 0.000057  time: 4.714858\n",
      "136 \t\t 0.000054  time: 4.705538\n",
      "137 \t\t 0.000051  time: 4.838171\n",
      "138 \t\t 0.000049  time: 4.646915\n",
      "139 \t\t 0.000046  time: 4.860081\n",
      "140 \t\t 0.000044  time: 5.615265\n",
      "141 \t\t 0.000042  time: 6.014156\n",
      "142 \t\t 0.000040  time: 4.685072\n",
      "143 \t\t 0.000038  time: 4.675933\n",
      "144 \t\t 0.000036  time: 4.451950\n",
      "145 \t\t 0.000034  time: 4.440140\n",
      "146 \t\t 0.000032  time: 4.095552\n",
      "147 \t\t 0.000031  time: 4.249479\n",
      "148 \t\t 0.000029  time: 4.215237\n",
      "149 \t\t 0.000028  time: 4.154069\n",
      "150 \t\t 0.000026  time: 4.134037\n",
      "151 \t\t 0.000025  time: 4.147752\n",
      "152 \t\t 0.000024  time: 4.156428\n",
      "153 \t\t 0.000023  time: 4.056557\n",
      "154 \t\t 0.000022  time: 4.108533\n",
      "155 \t\t 0.000021  time: 4.155508\n",
      "156 \t\t 0.000020  time: 4.193292\n",
      "157 \t\t 0.000019  time: 4.158690\n",
      "158 \t\t 0.000018  time: 4.154699\n",
      "159 \t\t 0.000017  time: 4.250876\n",
      "160 \t\t 0.000016  time: 4.088738\n",
      "161 \t\t 0.000015  time: 4.087646\n",
      "162 \t\t 0.000015  time: 4.167382\n",
      "163 \t\t 0.000014  time: 4.141081\n",
      "164 \t\t 0.000013  time: 4.264203\n",
      "165 \t\t 0.000013  time: 4.139294\n",
      "166 \t\t 0.000012  time: 4.141879\n",
      "167 \t\t 0.000011  time: 4.198039\n",
      "168 \t\t 0.000011  time: 4.145325\n",
      "169 \t\t 0.000010  time: 4.142042\n",
      "170 \t\t 0.000010  time: 4.127943\n",
      "171 \t\t 0.000009  time: 4.266853\n",
      "172 \t\t 0.000009  time: 4.144874\n",
      "173 \t\t 0.000008  time: 4.204833\n",
      "174 \t\t 0.000008  time: 4.035181\n",
      "175 \t\t 0.000008  time: 4.035507\n",
      "176 \t\t 0.000007  time: 4.182258\n",
      "177 \t\t 0.000007  time: 4.126345\n",
      "178 \t\t 0.000007  time: 4.064234\n",
      "179 \t\t 0.000006  time: 4.144947\n",
      "180 \t\t 0.000006  time: 4.023260\n",
      "181 \t\t 0.000006  time: 4.031232\n",
      "182 \t\t 0.000006  time: 4.175710\n",
      "183 \t\t 0.000005  time: 4.116325\n",
      "184 \t\t 0.000005  time: 4.147167\n",
      "185 \t\t 0.000005  time: 4.125384\n",
      "186 \t\t 0.000005  time: 4.107293\n",
      "187 \t\t 0.000004  time: 4.066713\n",
      "188 \t\t 0.000004  time: 4.168024\n",
      "189 \t\t 0.000004  time: 4.161688\n",
      "190 \t\t 0.000004  time: 4.067834\n",
      "191 \t\t 0.000004  time: 4.058358\n",
      "192 \t\t 0.000003  time: 4.211019\n",
      "193 \t\t 0.000003  time: 4.132895\n",
      "194 \t\t 0.000003  time: 4.708775\n",
      "195 \t\t 0.000003  time: 4.439664\n",
      "196 \t\t 0.000003  time: 4.215200\n",
      "197 \t\t 0.000003  time: 4.183126\n",
      "198 \t\t 0.000003  time: 4.215023\n",
      "199 \t\t 0.000002  time: 4.056548\n",
      "200 \t\t 0.000002  time: 4.187010\n",
      "201 \t\t 0.000002  time: 4.280155\n",
      "202 \t\t 0.000002  time: 4.161967\n",
      "203 \t\t 0.000002  time: 4.154940\n",
      "204 \t\t 0.000002  time: 4.203375\n",
      "205 \t\t 0.000002  time: 4.184359\n",
      "206 \t\t 0.000002  time: 4.207976\n",
      "207 \t\t 0.000002  time: 4.200478\n",
      "208 \t\t 0.000002  time: 4.173004\n",
      "209 \t\t 0.000002  time: 4.196686\n",
      "210 \t\t 0.000002  time: 4.182236\n",
      "211 \t\t 0.000001  time: 4.192104\n",
      "212 \t\t 0.000001  time: 4.134269\n",
      "213 \t\t 0.000001  time: 4.184595\n",
      "214 \t\t 0.000001  time: 4.196988\n",
      "215 \t\t 0.000001  time: 4.176884\n",
      "216 \t\t 0.000001  time: 4.152132\n",
      "217 \t\t 0.000001  time: 4.236493\n",
      "218 \t\t 0.000001  time: 4.248260\n",
      "219 \t\t 0.000001  time: 4.213163\n",
      "220 \t\t 0.000001  time: 4.164560\n",
      "221 \t\t 0.000001  time: 4.142833\n",
      "222 \t\t 0.000001  time: 4.388498\n",
      "223 \t\t 0.000001  time: 5.312199\n",
      "224 \t\t 0.000001  time: 4.497036\n",
      "225 \t\t 0.000001  time: 4.955706\n",
      "226 \t\t 0.000001  time: 4.803540\n",
      "227 \t\t 0.000001  time: 5.012659\n",
      "228 \t\t 0.000001  time: 3.998434\n",
      "229 \t\t 0.000001  time: 4.948027\n",
      "230 \t\t 0.000001  time: 4.408671\n",
      "231 \t\t 0.000001  time: 4.558482\n",
      "232 \t\t 0.000001  time: 4.320236\n",
      "233 \t\t 0.000001  time: 4.081547\n",
      "234 \t\t 0.000001  time: 4.042085\n",
      "235 \t\t 0.000000  time: 3.985436\n",
      "236 \t\t 0.000000  time: 4.006152\n",
      "237 \t\t 0.000000  time: 4.842221\n",
      "238 \t\t 0.000000  time: 5.647828\n",
      "239 \t\t 0.000000  time: 4.866900\n",
      "240 \t\t 0.000000  time: 4.694357\n",
      "241 \t\t 0.000000  time: 4.731350\n",
      "242 \t\t 0.000000  time: 4.791032\n",
      "243 \t\t 0.000000  time: 4.658349\n",
      "244 \t\t 0.000000  time: 4.620986\n",
      "245 \t\t 0.000000  time: 4.591678\n",
      "246 \t\t 0.000000  time: 5.253316\n",
      "247 \t\t 0.000000  time: 5.257895\n",
      "248 \t\t 0.000000  time: 5.134988\n",
      "249 \t\t 0.000000  time: 5.534210\n",
      "250 \t\t 0.000000  time: 4.808919\n"
     ]
    }
   ],
   "source": [
    "# Create user-by-item matrix - nothing to do here\n",
    "train_user_item = train_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "train_data_np = np.array(train_data_df)\n",
    "\n",
    "# Fit FunkSVD with the specified hyper parameters to the training data\n",
    "user_mat, movie_mat = FunkSVD(train_data_np, latent_features=15, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have created the **user_mat** and **movie_mat**, we can use this to make predictions for how users would rate movies, by just computing the dot product of the row associated with a user and the column associated with the movie.\n",
    "\n",
    "`3.` Use the comments in the function below to complete the **predict_rating** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_rating(user_matrix, movie_matrix, user_id, movie_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_matrix - user by latent factor matrix\n",
    "    movie_matrix - latent factor by movie matrix\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    \n",
    "    OUTPUT:\n",
    "    pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "    '''\n",
    "    # Use the training data to create a series of users and movies that matches the ordering in training data\n",
    "    \n",
    "    \n",
    "    # User row and Movie Column\n",
    "    \n",
    "    # Take dot product of that row and column in U and V to make prediction\n",
    "   \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function with the first user-movie in the user-movie matrix (notice this is a nan)\n",
    "pred_val = predict_rating(user_mat, movie_mat, 8, 2844)\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is great that you now have a way to make predictions. However it might be nice to get a little phrase back about the user, movie, and rating.\n",
    "\n",
    "`4.` Use the comments in the function below to complete the **predict_rating** function.  \n",
    "\n",
    "**Note:** The movie name doesn't come back in a great format, so you can see in the solution I messed around with it a bit just to make it a little nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_prediction_summary(user_id, movie_id, prediction):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    prediction - the predicted rating for user_id-movie_id\n",
    "    \n",
    "    OUTPUT:\n",
    "    None - prints a statement about the user, movie, and prediction made\n",
    "    \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your function the the results of the previous function\n",
    "print_prediction_summary(8, 2844, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the ability to make predictions, let's see how well our predictions do on the test ratings we already have.  This will give an indication of how well we have captured the latent features, and our ability to use the latent features to make predictions in the future!\n",
    "\n",
    "`5.` For each of the user-movie rating in the **val_df** dataset, compare the actual rating given to the prediction you would make.  How do your predictions do?  Do you run into any problems?  If yes, what is the problem?  Use the document strings and comments below to assist as you work through these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_comparison(val_df, num_preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    val_df - the validation dataset created in the third cell above\n",
    "    num_preds - (int) the number of rows (going in order) you would like to make predictions for\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing returned - print a statement about the prediciton made for each row of val_df from row 0 to num_preds\n",
    "    '''\n",
    "        \n",
    "# Perform the predicted vs. actual for the first 6 rows.  How does it look?\n",
    "validation_comparison(val_df, 6)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the predicted vs. actual for the first 7 rows.  What happened?\n",
    "validation_comparison(val_df, 7)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** A statement about why you think what happened happened.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
